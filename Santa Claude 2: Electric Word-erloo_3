{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"competition","sourceId":88046,"databundleVersionId":10229277},{"sourceType":"datasetVersion","sourceId":10327198,"datasetId":4581967,"databundleVersionId":10633860},{"sourceType":"modelInstanceVersion","sourceId":104492,"databundleVersionId":9473649,"modelInstanceId":72255},{"sourceType":"kernelVersion","sourceId":214761119}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"notebook started..\")\n!pip install -q -U transformers --no-index --find-links /kaggle/input/hf-libraries/transformers\n!pip install -q -U accelerate --no-index --find-links /kaggle/input/hf-libraries/accelerate\n!pip install -q -U bitsandbytes --no-index --find-links /kaggle/input/hf-libraries/bitsandbytes\nprint(\"pip installs done!\")\n\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\nfrom collections import OrderedDict\nfrom math import exp\n\nimport torch.nn.functional as F\n\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:06:57.757161Z","iopub.execute_input":"2024-12-29T18:06:57.757756Z","iopub.status.idle":"2024-12-29T18:07:19.870768Z","shell.execute_reply.started":"2024-12-29T18:06:57.757710Z","shell.execute_reply":"2024-12-29T18:07:19.870049Z"}},"outputs":[{"name":"stdout","text":"notebook started..\n^C\nTraceback (most recent call last):\n  File \"/opt/conda/bin/pip\", line 10, in <module>\n    sys.exit(main())\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 77, in main\n    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n    module = importlib.import_module(module_path)\n  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/commands/install.py\", line 15, in <module>\n    from pip._internal.cli.req_command import (\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 20, in <module>\n    from pip._internal.index.collector import LinkCollector\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/index/collector.py\", line 37, in <module>\n    from pip._internal.network.session import PipSession\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/network/session.py\", line 32, in <module>\n    from pip._vendor.cachecontrol import CacheControlAdapter as _BaseCacheControlAdapter\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n  File \"<frozen importlib._bootstrap_external>\", line 975, in get_code\n  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\nKeyboardInterrupt\npip installs done!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Reload prior submission.csv and optimize from that!!!\n* Set `reuse_last_submission = False` to start fresh\n* Specify any samples we don't think need further optimization\n* Specify any samples we want to fully shuffle between optimization rounds (stuck at local optimum)","metadata":{}},{"cell_type":"code","source":"# Set to False to do a \"clean\" run\nreuse_last_submission = True\n\nif reuse_last_submission:\n    samples = pd.read_csv(\"/kaggle/input/santa-best-code/submission.csv\")    \nelse:\n    samples = pd.read_csv(\"/kaggle/input/santa-2024/sample_submission.csv\")\n\n# If we think some items are well-optimized - including them here will skip them\nskip = [0,1,2,4,5]\n\n# If some samples are badly stuck at local optimum - we fully shuffle between rounds\nshuffle_between_cycles = [3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:07:19.872643Z","iopub.execute_input":"2024-12-29T18:07:19.873205Z","iopub.status.idle":"2024-12-29T18:07:19.890323Z","shell.execute_reply.started":"2024-12-29T18:07:19.873167Z","shell.execute_reply":"2024-12-29T18:07:19.889719Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Sorting sample 6 -[StopWords First]\n* Borrowing some help from...\n  \n## https://www.kaggle.com/code/asalhi/sorting-sample-6-stopwords-first","metadata":{}},{"cell_type":"code","source":"#from nltk.corpus import stopwords\n#import nltk\n#import numpy as np\n\n# Download stopwords if needed\n#nltk.download('stopwords')\n#stop_words = set(stopwords.words('english'))\n\n#def custom_sort(text):\n#    words = text.split()\n#    stop_words_in_text = sorted([word for word in words if word.lower() in stop_words])\n#    other_words = sorted([word for word in words if word.lower() not in stop_words])\n#    return \" \".join(stop_words_in_text + other_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:07:19.891327Z","iopub.execute_input":"2024-12-29T18:07:19.892064Z","iopub.status.idle":"2024-12-29T18:07:19.896020Z","shell.execute_reply.started":"2024-12-29T18:07:19.892025Z","shell.execute_reply":"2024-12-29T18:07:19.895117Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Apply the sorting to sample 2 (index 1)\n#samples.loc[1, \"text\"] = custom_sort(samples.loc[1, \"text\"])\nsamples.loc[1,\"text\"] = \"reindeer sleep walk the night and drive mistletoe scrooge laugh gingerbread bake chimney elf jump ornament give family advent fireplace\"\n#\"reindeer mistletoe ornament gingerbread bake the night walk and sleep scrooge drive fireplace chimney jump elf laugh give family advent\"\n#\"advent and bake chimney drive elf family fireplace gingerbread give jump laugh mistletoe night ornament reindeer scrooge sleep the walk\"\n#\"walk the reindeer ornament scrooge sleep night mistletoe laugh jump give gingerbread fireplace family elf drive chimney bake and advent\"\n#\"reindeer walk gingerbread bake the night and sleep scrooge drive chimney jump elf laugh mistletoe give family advent fireplace ornament\"\n#reindeer jump walk gingerbread bake the night and sleep scrooge drive elf laugh mistletoe give family advent fireplace chimney ornament","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:07:19.897800Z","iopub.execute_input":"2024-12-29T18:07:19.898119Z","iopub.status.idle":"2024-12-29T18:07:19.908655Z","shell.execute_reply.started":"2024-12-29T18:07:19.898095Z","shell.execute_reply":"2024-12-29T18:07:19.907780Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Batch-enabled scorer\n* Re-enabled 8-bit quantization\n* Make use of T4x2 setup\n* Credit: https://www.kaggle.com/code/cdeotte/brute-force-first-sample-perplexity-470","metadata":{}},{"cell_type":"code","source":"class LRUCache:\n    def __init__(self, capacity=10**11):\n        self.capacity = capacity\n        self.cache = OrderedDict()\n\n    def get(self, key):\n        if key in self.cache:\n            self.cache.move_to_end(key)\n            return self.cache[key]\n        return None\n\n    def set(self, key, value):\n        self.cache[key] = value\n        self.cache.move_to_end(key)\n        if len(self.cache) > self.capacity:\n            self.cache.popitem(last=False)\n\n    def __len__(self):\n        return len(self.cache)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:07:19.909610Z","iopub.execute_input":"2024-12-29T18:07:19.909917Z","iopub.status.idle":"2024-12-29T18:07:19.922012Z","shell.execute_reply.started":"2024-12-29T18:07:19.909882Z","shell.execute_reply":"2024-12-29T18:07:19.921331Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import gc\nimport os\nfrom math import exp\nfrom collections import Counter\nfrom typing import List, Optional, Union\n\nimport numpy as np\nimport pandas as pd\nimport transformers\nimport torch\n\nos.environ['OMP_NUM_THREADS'] = '1'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nPAD_TOKEN_LABEL_ID = torch.nn.CrossEntropyLoss().ignore_index\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\nclass PerplexityCalculator:\n    model_kwargs = {\n        \"attn_implementation\": \"sdpa\",\n        \"device_map\": \"auto\",\n        \"torch_dtype\": torch.float16,\n    }\n    device = torch.device('cuda')\n\n    def __init__(self,  model_path: str = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\", capacity=10**11):\n        self.tokenizer = transformers.AutoTokenizer.from_pretrained(model_path, padding_side=\"right\")\n        self.model = transformers.AutoModelForCausalLM.from_pretrained(model_path, **self.model_kwargs)\n        self.loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n        self.pad_token_label_id = self.loss_fct.ignore_index\n\n        self.model.eval()\n        self.cache = LRUCache(capacity=capacity)\n\n\n    def get_perplexity(self, input_texts, batch_size=128, use_cache=True, verbose=False):\n        single_input = isinstance(input_texts, str)\n        input_texts = [input_texts] if single_input else input_texts\n        \n        results = [None] * len(input_texts)\n        \n        if use_cache:\n            text_to_process = []\n            for i, text in enumerate(input_texts):\n                cached_val = self.cache.get(text)\n                if cached_val is not None:\n                    results[i] = cached_val\n                else:\n                    text_to_process.append(text)\n        else:\n            text_to_process = input_texts.copy()\n\n        loss_list = []\n        batches = len(text_to_process)//batch_size + (len(text_to_process)%batch_size != 0)\n        pbar = range(batches)\n\n        if verbose and batches:\n            pbar = tqdm(range(batches))\n\n        for j in pbar:\n\n            a = j*batch_size\n            b = (j+1)*batch_size\n            input_batch = text_to_process[a:b]\n\n            with torch.no_grad():\n\n                # Explicitly add sequence boundary tokens to the text\n                text_with_special = [f\"{self.tokenizer.bos_token}{text}{self.tokenizer.eos_token}\" for text in input_batch]\n\n                # Tokenize\n                model_inputs = self.tokenizer(\n                    text_with_special,\n                    return_tensors='pt',\n                    add_special_tokens=False,\n                    padding=True,\n                )\n\n                if 'token_type_ids' in model_inputs:\n                    model_inputs.pop('token_type_ids')\n\n                model_inputs = {k: v.to(self.device ) for k, v in model_inputs.items()}\n\n                # Get model output\n                output = self.model(**model_inputs, use_cache=False)\n                logits = output['logits']\n\n                label = model_inputs['input_ids']\n                label[label == self.tokenizer.pad_token_id] = self.pad_token_label_id\n\n                # Shift logits and labels for calculating loss\n                shift_logits = logits[..., :-1, :].contiguous()  # Drop last prediction\n                shift_labels = label[..., 1:].contiguous()  # Drop first input\n\n                # Calculate token-wise loss\n                loss = self.loss_fct(\n                    shift_logits.view(-1, shift_logits.size(-1)),\n                    shift_labels.view(-1)\n                )\n\n                loss = loss.view(len(logits), -1)\n                valid_length = (shift_labels != self.pad_token_label_id).sum(dim=-1)\n                loss = torch.sum(loss, -1) / valid_length\n\n                loss_list += loss.cpu().tolist()\n\n        ppl = [exp(i) for i in loss_list]\n\n        index_ppl = 0\n        for index_el, el in enumerate(results):\n            if el is None:\n                results[index_el] = ppl[index_ppl]\n                self.cache.set(text_to_process[index_ppl], ppl[index_ppl])\n                index_ppl += 1\n        return results[0] if single_input else results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:07:19.923231Z","iopub.execute_input":"2024-12-29T18:07:19.923543Z","iopub.status.idle":"2024-12-29T18:07:20.427340Z","shell.execute_reply.started":"2024-12-29T18:07:19.923509Z","shell.execute_reply":"2024-12-29T18:07:20.426655Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Load custom scorer","metadata":{}},{"cell_type":"code","source":"#gemma-2-9b (competition scoring metric)\nscorer = PerplexityCalculator('/kaggle/input/gemma-2/transformers/gemma-2-9b/2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:07:20.428318Z","iopub.execute_input":"2024-12-29T18:07:20.428634Z","iopub.status.idle":"2024-12-29T18:09:58.003757Z","shell.execute_reply.started":"2024-12-29T18:07:20.428609Z","shell.execute_reply":"2024-12-29T18:09:58.002821Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4172fb61a51a401abf71fcebec44390d"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# Get our starting scores\n* On initial dataset scorer returns some NaN's - we'll account for that..\n* Since we've re-run this notebook a few times - further re-runs may not improve the score much...","metadata":{}},{"cell_type":"code","source":"%%time\n# Get actual mean value \nscores = []\nfor row in range(len(samples)):\n    score = scorer.get_perplexity(samples.iloc[row].text, batch_size=2, use_cache=True, verbose=False)\n    print(samples.iloc[row].text)\n    print(f\"Score: {score:.2f}\\n\")\n    scores.append(score)\n\nprint(f\"Starting mean score: {np.mean(scores):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:09:58.004903Z","iopub.execute_input":"2024-12-29T18:09:58.005280Z","iopub.status.idle":"2024-12-29T18:10:09.551884Z","shell.execute_reply.started":"2024-12-29T18:09:58.005254Z","shell.execute_reply":"2024-12-29T18:10:09.550944Z"}},"outputs":[{"name":"stderr","text":"Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"reindeer mistletoe elf gingerbread family advent scrooge chimney fireplace ornament\nScore: 468.96\n\nreindeer sleep walk the night and drive mistletoe scrooge laugh gingerbread bake chimney elf jump ornament give family advent fireplace\nScore: 439.19\n\nsleigh yuletide beard carol cheer chimney decorations gifts grinch holiday holly jingle magi naughty nice nutcracker ornament polar workshop stocking\nScore: 297.48\n\nsleigh of the magi yuletide cheer is unwrap gifts relax and eat cheer decorations carol sing chimney visit workshop grinch holiday holly jingle naughty nice nutcracker polar beard ornament stocking\nScore: 195.81\n\nof and to in the as you that it we with from have not night season eggnog milk chocolate candy peppermint cookie fruitcake toy doll game puzzle greeting card wrapping paper bow wreath poinsettia star angel snowglobe candle fireplace wish dream believe wonder hope joy peace merry hohoho kaggle workshop\nScore: 67.61\n\nfrom and and as and have the in is it of not that the to we with you yuletide cheer advent angel bake beard believe bow candy candle carol cheer chocolate chimney cookie decorations doll dream drive eat eggnog elf family fireplace fireplace chimney fruitcake game give gifts gingerbread grinch greeting card holly hohoho holiday hope jingle jump joy kaggle laugh magi merry milk mistletoe naughty nice night nutcracker ornament ornament of the night peace peppermint polar poinsettia puzzle reindeer relax scrooge season sing sleigh sleep snowglobe star stocking toy unwrap visit walk wish wonder workshop workshop wreath wrapping paper\nScore: 33.37\n\nStarting mean score: 250.40\nCPU times: user 6.36 s, sys: 983 ms, total: 7.34 s\nWall time: 11.5 s\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Our \"Simulated Annealing\" Implementation\n\nKey parameters for this optimizer:\n\n1. Temperature progression:\n   - Starts at `temp_start=3.0`, increases by `temp_start_increase_per_cycle=1.0` each cycle\n   - Each cycle cools to `temp_end=0.2` using `cooling_rate=0.95`\n   - Runs total of `reheat_cycles=8` cycles (so final cycle starts at 10.0)\n\n2. Temperature step behavior:\n   - Makes `steps_per_temp=170` attempts at each temperature level\n   - This **results in a ~5 hour runtime** (assuming samples 0 and 5 are skipped)\n   - When improvements found, temporarily drops to `temp_end` for cycles by `low_temp_samples_after_improve`\n   - Returns to original temperature to continue cooling cycle\n\n3. Batch processing efficiency:\n   - Evaluates up to `max_batch_size=64` arrangements simultaneously\n   - Limits total words processed to `max_words_per_batch=640` to manage memory\n   - Automatically adjusts batch size based on sequence length\n\n4. Between-cycle behavior:\n   - Maintains best arrangement found across all cycles\n   - Has `shuffle_chance_between_cycles=0.0` probability of randomizing sequence\n   - Each new cycle starts at higher temperature to explore further from optimum\n\n### Understanding Temperature and Acceptance Probabilities\nAcceptance probability = exp(-delta/T), where delta is score difference and T is temperature\n\n* At max temp (10.0): +1 worse: 90% chance, +5: 61%, +10: 37%, +20: 14%\n* At starting temp (3.0): +1 worse: 72% chance, +5: 19%, +10: 4%, +20: 0.1%\n* At min temp (0.2): +1 worse: 0.67% chance, +5 or worse: ≈0%\n\nBetter-scoring arrangements are always accepted. Higher temperatures allow exploring further from current solution, while minimum temperature mainly accepts improvements.\n   \nProgress indicators:\n* `>` - found a new best score\n* `<` - accepted a worse score (for exploration)\n* `-` - rejected the new arrangement (only prints 10% of the time)\n* `x` - skipped invalid arrangement (NaN score)","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"# ******************** mutate_sentence *********************\n# Make a small change to a list of words\n# Picks one of 5 possible mutations to the list\n# - swap 2 words\n# - remove 1 word and reinsert it at random\n# - pick 4 indices and shuffle the words at those locations\n# - remove a segment of words and reinsert it at random\n# - same as above, but flip the segment\ndef mutate_sentence(sentence_in):\n    sentence = sentence_in.copy()\n    #print('       , , ',  sentence)\n    n = len(sentence)\n   \n    if np.random.randint(100) < 80: # make a small mutation \n        if np.random.randint(100) < 33: # swap 2 words\n            i, j = random.sample(range(n), 2)\n            sentence[i], sentence[j] = sentence[j], sentence[i]\n            #print('swap',i, j,  sentence)\n            return(sentence)\n        elif  np.random.randint(100) < 50:                           # shift 1 word to another spot\n            i = np.random.choice(n) # word in slot i\n            j = np.random.choice(n) # slot j\n            t = sentence.pop(i)\n            sentence.insert(j, t)\n            #print('shift',i, j,  sentence)\n            return(sentence)\n        else:  # pick 4 random slots and permute the words in place\n            t = 4\n            p0 = random.sample(range(n), t)\n            #print(p0)\n            p1 = random.sample(p0, t)\n            #print(p1)\n            sentence[p0[0]], sentence[p0[1]], sentence[p0[2]], sentence[p0[3]] = sentence[p1[0]], sentence[p1[1]], sentence[p1[2]], sentence[p1[3]]\n            if n != len(sentence): print('I fail at math')\n            #print('       , , ',  sentence)\n        return(sentence)\n     # otherwise make a larger change - we'll move a segment\n    i, j = random.sample(range(n + 1), 2)\n    if i > j: i, j = j, i\n   \n    if np.random.randint(100) < 90:   # pick a random segment and relocate it\n        segment = sentence[i:j]\n        remains = sentence[:i]\n        if j < n: remains = remains + sentence[j:]\n        t = np.random.choice(len(remains)+ 1) # insert it here\n        sentence = remains[:t] + segment + remains[t:]\n        if n != len(sentence): print('I fail at math')\n        #print('segment',i, j,  sentence)\n        return(sentence)\n    else:            # pick a random segment, reverse it and relocate that\n        segment = sentence[i:j]\n        segment.reverse()\n        remains = sentence[:i]\n        if j < n: remains = remains + sentence[j:]\n        t = np.random.choice(len(remains)+ 1) # insert it here\n        sentence = remains[:t] + segment + remains[t:]\n        if n != len(sentence): print('mutate_sentence() has gone very wrong')\n        #print('segment',i, j,  sentence)\n        return(sentence)\n    return(sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:09.552917Z","iopub.execute_input":"2024-12-29T18:10:09.553386Z","iopub.status.idle":"2024-12-29T18:10:09.564887Z","shell.execute_reply.started":"2024-12-29T18:10:09.553358Z","shell.execute_reply":"2024-12-29T18:10:09.563922Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"This is the mutation function used for SA:","metadata":{}},{"cell_type":"code","source":"def mutate(child):\n    # 候補リスト\n    mutation_types = ['swap2', 'swap3', 'swap', 'sort', 'sort2', 'shift', 'shiftlarge', 'inversion', 'scramble']\n    \n    # インデックスが若いほど大きい重みを付ける\n    # 例: [9, 8, 7, 6, 5, 4, 3, 2, 1] のような降順\n    n = len(mutation_types)\n    weights = [1 for i in range(n)]  # 9,8,7,...,1\n    \n    # 重み付きで1つ選択する\n    mutation_type = random.choices(mutation_types, weights=weights, k=1)[0]\n    #child = child.split() # Convert child to a list of words \n    n = len(child) \n    if mutation_type == \"swap2\":\n        i,j = random.sample(range(n),2)\n        child[i], child[j] = child[j], child[i] \n    elif mutation_type == \"swap3\":\n        i,j,k = random.sample(range(n),3)\n        child[i], child[j], child[k] = child[j], child[k], child[i] \n    elif mutation_type == 'swap': \n        #mutation_size = random.randint(1, n//3) \n        mutation_size = random.randint(1, 4)\n        for _ in range(mutation_size): \n            i, j = random.sample(range(n), 2) \n            child[i], child[j] = child[j], child[i] \n    elif mutation_type == \"sort\":\n        segment_length = random.randint(3, n) \n        start = random.randint(0, n - segment_length) \n        end = start + segment_length\n        child[start:end] = sorted(child[start:end])\n    elif mutation_type == \"sort2\":\n        segment_length = random.randint(3, n) \n        start = random.randint(0, n - segment_length) \n        end = start + segment_length\n        child[start:end] = sorted(child[start:end])\n    elif mutation_type == 'shift':\n        i = np.random.choice(n) # word in slot i\n        j = np.random.choice(n) # slot j\n        t = child.pop(i)\n        child.insert(j, t)\n    elif mutation_type == 'shiftlarge':\n        i = np.random.randint(0, n-1) # word in slot i \n        k = np.random.randint(1, 4) # length of the segment to move (1 to 4) \n        j = np.random.randint(0, n-1)\n        # Ensure j is not within the segment to be moved \n        while j >= i and j <= i + k - 1: \n            j = np.random.randint(0, n-1)\n        # Extract the segment and remove it from the list \n        t = child[i:i+k] \n        del child[i:i+k] \n        # Insert the segment at the new position \n        for index, word in enumerate(t): \n            child.insert(j + index, word)\n    elif mutation_type == 'inversion': \n        segment_length = random.randint(3, 5) \n        start = random.randint(0, n - segment_length) \n        end = start + segment_length - 1\n        child[start:end + 1] = reversed(child[start:end + 1])\n    elif mutation_type == 'scramble': \n        segment_length = random.randint(3, 5) \n        start = random.randint(0, n - segment_length) \n        end = start + segment_length - 1 \n        subset = child[start:end+1] \n        random.shuffle(subset) \n        child[start:end+1] = subset \n    elif mutation_type == \"shuffle\":\n        random.shuffle(child)\n    return child #\" \".join(child)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:09.568682Z","iopub.execute_input":"2024-12-29T18:10:09.568983Z","iopub.status.idle":"2024-12-29T18:10:09.583468Z","shell.execute_reply.started":"2024-12-29T18:10:09.568957Z","shell.execute_reply":"2024-12-29T18:10:09.582790Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Change the parameters here:","metadata":{}},{"cell_type":"code","source":"from sortedcontainers import SortedSet, SortedList, SortedDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:09.584286Z","iopub.execute_input":"2024-12-29T18:10:09.584494Z","iopub.status.idle":"2024-12-29T18:10:09.599135Z","shell.execute_reply.started":"2024-12-29T18:10:09.584472Z","shell.execute_reply":"2024-12-29T18:10:09.598340Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"math.log(0.1)/math.log(0.8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:09.600170Z","iopub.execute_input":"2024-12-29T18:10:09.600404Z","iopub.status.idle":"2024-12-29T18:10:09.606211Z","shell.execute_reply.started":"2024-12-29T18:10:09.600381Z","shell.execute_reply":"2024-12-29T18:10:09.605374Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"10.318851158516171"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# temp_start = 1 #30 #30 #50 #3.0                      # Initial temperature for first cycle\n# temp_end = 0.1                        # Final/minimum temperature\n# reheat_cycles = 2  #8                   # Number of full heating/cooling cycles to run\n# temp_start_increase_per_cycle = 1.0 #1  # How much to increase starting temp each cycle\n# cooling_rate = 0.80 #0.95                   # Temperature reduction multiplier each step \n# steps_per_temp = 300 #170 #300 #170                   # Attempts at each temperature level\n# low_temp_samples_after_improve = steps_per_temp * 5  # Samples done at min temp after improvements (extends cycle)\n# max_batch_size = 64           # Maximum sequences to evaluate at once\n# max_words_per_batch = 640            # Total word limit per batch to manage memory\n# shuffle_chance_between_cycles = 1.0   # Probability of completely shuffling the sequence between cycles\n# max_len_text_que = 100\n# initial_trials = 10\n\n# # 空白文字で単語に分割\n# def split_into_words(char_list):\n#     words = ''.join(char_list).split(' ')  # リストを文字列に結合し、空白で分割\n#     return words\n\n\n\n# def simulated_annealing_optimize(text: str, pretext = \"\", temp_start=temp_start, temp_end=temp_end, \n#                                cooling_rate=cooling_rate, samples_per_temp=steps_per_temp, \n#                                max_batch_size=max_batch_size, max_words_per_batch=max_words_per_batch,\n#                                reheat_cycles=reheat_cycles, low_temp_samples_after_improve=low_temp_samples_after_improve, shuffle_chance_between_cycles = shuffle_chance_between_cycles, verbose=False,\n#                                 max_len_text_que = max_len_text_que, initial_trials=initial_trials):\n#     text_que = SortedSet()\n#     print(f\"text: {text}\")\n\n#     words_list = text.split()\n#     # text = f\"'{text}'\"\n#     # print(f\"text: {text}\")\n#     score = scorer.get_perplexity(text)\n#     # print(f\"words_list: {words_list}, joined_text: {' '.join(words_list)}\")\n#     text_que.add((score, tuple(words_list), temp_start))\n#     best = ''\n#     best_score = 1 << 60\n#     print(f\"これからSAでの探索を開始します.\")\n#     while len(text_que) > 0:\n#         current_score, current_tuple, current_temp = text_que.pop()\n#         current = list(current_tuple)  # リストに戻す\n        \n#         # print(f\"current:{current}\")\n#         # 単語リスト\n#         # current = split_into_words(current)\n#         current_temp *= cooling_rate\n#         print(f\"current_score: {current_score}, current: {' '.join(current)}\")\n        \n#         neighbors = []\n#         neighbor_texts = []\n#         for _ in range(max_batch_size):\n#             neighbor = current.copy()\n#             neighbor = mutate(neighbor)\n#             neighbors.append(neighbor)\n#             neighbor_texts.append(pretext + ' '.join(neighbor))\n#             # print(f\"neighbor_text: {' '.join(neighbor)}\")\n        \n#         neighbor_scores = scorer.get_perplexity(neighbor_texts, batch_size=max_batch_size, use_cache=True, verbose=False)\n#         for neighbor, neighbor_score in zip(neighbors, neighbor_scores):\n#             if math.isnan(neighbor_score):\n#                 if verbose:\n#                     print(\"x\", end=\"\", flush=True)\n#                 continue\n#             if best_score * 1.5 < neighbor_score:\n#                 continue\n#             delta = neighbor_score - current_score\n#             # if delta < 0 or random.random() < math.exp(-delta / current_temp):\n#             # 現在はランダム性が全くないので改善できそう\n            \n#             if delta < 0 or random.random() < math.exp(-delta / current_temp):\n#                 # print(f\"add_neighbor: {neighbor}\")\n#                 text_que.add((neighbor_score, tuple(neighbor), current_temp))\n#                 if best_score > neighbor_score:\n#                     best_score = neighbor_score\n#                     best = neighbor\n#                     print(f\"\\n best_score: {best_score}, {' '.join(best)}\")\n#         print(f\"len_text_que: {len(text_que)}, best_score: {best_score}\")\n#         while len(text_que) > max_len_text_que:\n#             text_que.pop()\n\n#     print(f\"best: {best}\")\n    \n#     return pretext + ' '.join(best), best_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:09.607442Z","iopub.execute_input":"2024-12-29T18:10:09.608187Z","iopub.status.idle":"2024-12-29T18:10:09.614436Z","shell.execute_reply.started":"2024-12-29T18:10:09.608161Z","shell.execute_reply":"2024-12-29T18:10:09.613718Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"for idx, row in samples.iterrows():\n    print(idx, row.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:09.615515Z","iopub.execute_input":"2024-12-29T18:10:09.615888Z","iopub.status.idle":"2024-12-29T18:10:09.630345Z","shell.execute_reply.started":"2024-12-29T18:10:09.615824Z","shell.execute_reply":"2024-12-29T18:10:09.629525Z"}},"outputs":[{"name":"stdout","text":"0 reindeer mistletoe elf gingerbread family advent scrooge chimney fireplace ornament\n1 reindeer sleep walk the night and drive mistletoe scrooge laugh gingerbread bake chimney elf jump ornament give family advent fireplace\n2 sleigh yuletide beard carol cheer chimney decorations gifts grinch holiday holly jingle magi naughty nice nutcracker ornament polar workshop stocking\n3 sleigh of the magi yuletide cheer is unwrap gifts relax and eat cheer decorations carol sing chimney visit workshop grinch holiday holly jingle naughty nice nutcracker polar beard ornament stocking\n4 of and to in the as you that it we with from have not night season eggnog milk chocolate candy peppermint cookie fruitcake toy doll game puzzle greeting card wrapping paper bow wreath poinsettia star angel snowglobe candle fireplace wish dream believe wonder hope joy peace merry hohoho kaggle workshop\n5 from and and as and have the in is it of not that the to we with you yuletide cheer advent angel bake beard believe bow candy candle carol cheer chocolate chimney cookie decorations doll dream drive eat eggnog elf family fireplace fireplace chimney fruitcake game give gifts gingerbread grinch greeting card holly hohoho holiday hope jingle jump joy kaggle laugh magi merry milk mistletoe naughty nice night nutcracker ornament ornament of the night peace peppermint polar poinsettia puzzle reindeer relax scrooge season sing sleigh sleep snowglobe star stocking toy unwrap visit walk wish wonder workshop workshop wreath wrapping paper\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Run and Submit!","metadata":{}},{"cell_type":"markdown","source":"Change the text to optimize here: either a full text, then use split afterwards (processing_words.split()). Or define the words, combining words which should processed together. A pretext or aftertext can also be added, it has to be added within the code (see #!!!!!!!!!!!!!!!!) and do not forget the empty space. This text has to be removed from the words and will be kept unchanged at the beginning (or end).","metadata":{}},{"cell_type":"code","source":"text = \"sleigh of holly yuletide cheer unwrap gifts eat holiday cheer relax sing carol the magi visit workshop grinch is naughty and nice decorations ornament chimney stocking nutcracker polar beard jingle\"\n\nscorer.get_perplexity(text, batch_size=1, use_cache=False, verbose=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:09.631297Z","iopub.execute_input":"2024-12-29T18:10:09.631627Z","iopub.status.idle":"2024-12-29T18:10:09.768334Z","shell.execute_reply.started":"2024-12-29T18:10:09.631592Z","shell.execute_reply":"2024-12-29T18:10:09.767616Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"198.05016083314254"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"\nneighbor_texts = []\nneighbor_scores = []\ncurrent = text.split()\nfor _ in tqdm(range(1000)):\n    neighbor = current.copy()\n    neighbor = mutate(neighbor)\n    neighbor_texts.append(' '.join(neighbor))\n    score = scorer.get_perplexity(' '.join(neighbor), batch_size=1, use_cache=False, verbose=False)\n    neighbor_scores.append(score)\n\n# print(f\"score: {score}\\n {neighbor}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:14:10.105237Z","iopub.execute_input":"2024-12-29T18:14:10.105630Z","iopub.status.idle":"2024-12-29T18:16:12.882220Z","shell.execute_reply.started":"2024-12-29T18:14:10.105598Z","shell.execute_reply":"2024-12-29T18:16:12.881292Z"},"_kg_hide-input":true},"outputs":[{"name":"stderr","text":"100%|██████████| 1000/1000 [02:02<00:00,  8.15it/s]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"best_id = neighbor_scores.index(min(neighbor_scores))\nprint(f\"score: {neighbor_scores[best_id]}\\ntext: {neighbor_texts[best_id]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:16:12.915435Z","iopub.execute_input":"2024-12-29T18:16:12.915706Z","iopub.status.idle":"2024-12-29T18:16:12.924067Z","shell.execute_reply.started":"2024-12-29T18:16:12.915680Z","shell.execute_reply":"2024-12-29T18:16:12.923268Z"}},"outputs":[{"name":"stdout","text":"score: 195.81076802453526\ntext: sleigh of the magi yuletide cheer is unwrap gifts relax and eat cheer decorations carol sing chimney visit workshop grinch holiday holly jingle naughty nice nutcracker polar beard ornament stocking\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 6))\nsns.histplot(neighbor_scores, bins=50, kde=False, color='gray')\nplt.title('Neighbor Scoresのヒストグラム')\nplt.xlabel('スコア')\nplt.ylabel('頻度')\nplt.xlim(150, 500)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:21.747508Z","iopub.execute_input":"2024-12-29T18:10:21.747748Z","iopub.status.idle":"2024-12-29T18:10:22.674739Z","shell.execute_reply.started":"2024-12-29T18:10:21.747724Z","shell.execute_reply":"2024-12-29T18:10:22.673900Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 38971 (\\N{CJK UNIFIED IDEOGRAPH-983B}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12498 (\\N{KATAKANA LETTER HI}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12473 (\\N{KATAKANA LETTER SU}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12488 (\\N{KATAKANA LETTER TO}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12464 (\\N{KATAKANA LETTER GU}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12521 (\\N{KATAKANA LETTER RA}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12512 (\\N{KATAKANA LETTER MU}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12467 (\\N{KATAKANA LETTER KO}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 12450 (\\N{KATAKANA LETTER A}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"submission = pd.DataFrame(columns=['id', 'text'])\nscores = []\ntexts = []\n# processing_words = ['magi yuletide cheer', 'grinch', 'carol', 'holly', 'jingle', 'naughty nice', \n#                     'nutcracker', 'polar', 'beard', 'ornament', 'stocking chimney', 'sleigh', \n#                     'holiday', 'workshop',  \n#                     'gifts', 'decorations']\n# processing_words = ['sleigh','naughty nice', 'grinch','gifts','magi','yuletide', 'workshop', 'nutcracker',\n#                     'holiday','holly jingle', 'carol', \n#                     'stocking', 'chimney', 'polar', 'beard', 'ornament',  \n#                     'decorations']\n# processing_words = ['sleigh of the magi', 'is', 'yuletide', 'cheer', 'unwrap gifts','relax', \n#                     'and', 'eat', 'holiday', 'decorations', 'holly jingle',\n#                     'carol','cheer', 'sing', 'chimney', 'visit', 'workshop',\n#                     'grinch naughty nice polar beard nutcracker ornament stocking']\n#processing_words = [\"from\", \"and\", \"as\", \"have\", \"in\", \"not\", \"it\", \"of\", \"that\", \"the\", \"to\", \"we\", \"with\", \"you\", \n#\"season greeting angel believe bow card candle candy chocolate cookie doll dream eggnog fireplace fruitcake game hohoho hope joy kaggle merry milk night peace peppermint poinsettia puzzle snowglobe star toy wreath wish workshop wonder wrapping paper\"]\n#processing_words = ['wreath', 'it', 'have', 'merry', 'season', 'hohoho', 'and to you', 'from the star', 'of', 'wonder', 'workshop', 'that night', 'not with', 'joy', \n#                    'as we', 'believe in', 'hope', 'peace', 'milk', 'cookie', 'eggnog', 'fruitcake', 'chocolate', 'candy', 'peppermint', 'candle', 'snowglobe', \n#                    'angel', 'poinsettia', 'wrapping paper', 'bow', 'greeting card', 'wish', 'dream', 'fireplace', 'kaggle', 'toy', 'doll', 'game', 'puzzle']\n# processing_words = [#\"from and as have in not it of that the to we with you season\",\n#                      'joy', 'wonder', 'dream', 'believe', 'wish', 'hope', 'peace', 'star', 'night',\n#                     'candle', 'wreath', 'angel', 'snowglobe', 'fireplace', 'poinsettia', 'candy',\n#                     'peppermint', 'chocolate', 'cookie', 'milk', 'eggnog', 'fruitcake',\n#                     \"greeting card wrapping paper bow toy doll game puzzle merry hohoho kaggle workshop\"]\n# processing_words = ['of', 'and', 'to', 'and', 'in', 'the', 'as', 'and', 'is', \n#                     'that', 'the', 'it', 'we', 'with', 'from', 'have', 'not', \n#                     'you yuletide cheer advent angel bake beard believe bow candy candle carol cheer chocolate chimney cookie decorations doll dream drive', \n#                     'eat eggnog elf family fireplace fireplace chimney fruitcake game give gifts gingerbread grinch greeting card', \n#                     'holly hohoho holiday hope jingle jump joy kaggle laugh magi merry milk mistletoe naughty nice night nutcracker', 'ornament ornament', 'of', 'the', \n#                     'night peace peppermint polar poinsettia puzzle reindeer relax scrooge season sing sleigh sleep snowglobe star stocking toy unwrap visit walk wish wonder workshop workshop wreath wrapping paper'\n#                     ]\n# processing_words = \"and and as have the in is it of the to we with you yuletide cheer advent and angel bake beard believe bow candy candle carol cheer chocolate chimney cookie decorations doll dream drive eat eggnog elf from family fireplace fireplace chimney fruitcake game give gifts gingerbread grinch greeting card holly hohoho holiday hope jingle jump joy kaggle laugh magi merry milk mistletoe naughty nice nutcracker not that night ornament ornament of the night peace peppermint polar poinsettia puzzle reindeer relax scrooge season sing sleigh sleep snowglobe star stocking toy unwrap visit walk wish wonder workshop workshop wreath wrapping paper\"\n# processing_words = \"and is of the sleigh yuletide beard cheer chimney decorations grinch holiday holly jingle magi naughty nice nutcracker ornament polar stocking workshop cheer carol eat sing relax visit unwrap gifts \"\n# processing_words = \"sleigh of the magi yuletide cheer is eat relax and unwrap gifts cheer grinch holiday holly jingle naughty nice nutcracker ornament polar beard workshop visit chimney stocking carol sing decorations\"\n# processing_words = [\"sleigh of the magi yuletide cheer is\", 'eat relax and unwrap gifts', 'cheer', 'grinch holiday holly jingle naughty nice nutcracker', 'ornament', 'polar', 'beard', 'visit workshop', 'chimney', 'stocking', 'carol sing', \"decorations\"]\n# processing_words = ['of', 'magi', 'yuletide cheer', 'and', 'unwrap', 'gifts', 'sing', 'carol','the','holly',  'jingle', 'eat', 'holiday', 'visit workshop', 'grinch', 'is', 'naughty', \n#                     'nice','relax','stocking', 'chimney', 'decorations', 'ornament', 'cheer', 'nutcracker', 'polar', 'beard']\n#processing_words = \"season joy wonder dream believe in wish and to you hope peace from the star of that night candle wreath angel snowglobe fireplace poinsettia candy peppermint chocolate cookie milk not eggnog fruitcake greeting card wrapping paper bow it toy doll game puzzle have merry hohoho as we with kaggle workshop\"\n#processing_words = \"magi yuletide grinch holiday cheer gifts decorations ornament stocking holly jingle sleigh carol naughty nice polar beard workshop chimney nutcracker\"\n#processing_words = \"sleigh of the magi yuletide cheer unwrap gifts relax and eat cheer carol sing holiday decorations holly jingle workshop visit grinch naughty is nice nutcracker ornament stocking chimney polar beard\"\nprocessing_words = \"grinch carol magi yuletide cheer holiday holly jingle naughty nice nutcracker polar beard ornament stocking chimney sleigh workshop gifts decorations\"\n#processing_words = processing_words.split()\n#processing_words = samples.loc[1,\"text\"].split()\n#processing_words = processing_words.split()\n#\"sleigh magi yuletide cheer gifts holiday decorations holly jingle carol chimney grinch naughty nice polar beard workshop nutcracker ornament stocking\"\n\n# Process each sample\nid_texts = {\n    3: 'sleigh yuletide is unwrap gifts of cheer eat jingle relax sing carol the magi visit workshop naughty and nice holiday holly cheer chimney grinch nutcracker polar beard ornament decorations stocking',\n    # 必要に応じて、他の id 用のテキストを追加できる\n    # たとえば 4: \"other text ...\"\n}\ntexts_id3 = [\n    \"sleigh yuletide beard carol cheer cheer chimney decorations eat gifts grinch holiday holly jingle is naughty and nice nutcracker ornament of the magi polar relax sing stocking unwrap visit workshop\", \n    \"sleigh and cheer cheer beard chimney carol decorations eat gifts grinch holiday holly jingle is naughty nice nutcracker ornament of the magi polar relax sing stocking unwrap visit workshop yuletide\"\n    ]\n        \n\nfor idx, row in samples.iterrows():\n\n    if idx in skip:\n        score = scorer.get_perplexity(row.text, batch_size = 1)\n        print(f\"Skipping sample {idx} ({score:.2f})\")\n        final_text = row.text\n    else:\n        print(f\"\\nProcessing sample {idx}...\")\n        text = samples.iloc[idx].text\n        print(f\"text: {text}\")\n        words_list = text.split()\n        fixed_word = words_list[0]\n        remaining_words = words_list[1:]\n        random.shuffle(remaining_words)\n        shuffled_words = [fixed_word] + remaining_words\n        shuffled_text = ' '.join(shuffled_words)\n        print(f\"shuffled_text: {shuffled_text}\")\n        \n        # 最適化関数の呼び出し\n        simulated_annealing_optimize(shuffled_text, verbose=True)\n        \n        print(\"正常に終了しました。\")\n        \n        \n        \n    \n    scores.append(score)\n   \n    # Add to submission dataframe\n    #submission.loc[idx] = {\n    #    'id': row.id,\n     #   'text': final_text\n    #}\n    #print(\"-\" * 80)\n\n# Print summary statistics\nprint(\"\\nScore Summary:\")\n\nfor i in range(len(scores)):\n   print(f\"Sample {i} final score: {scores[i]:.2f}\")\n\nprint(f\"Submission mean score: {np.mean(scores):.2f}\")\n\n# Save to CSV\n#submission.to_csv(\"submission.csv\", index=False)\n#print(\"\\nSubmission file created!\")\n\n#submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:22.676035Z","iopub.execute_input":"2024-12-29T18:10:22.676476Z","iopub.status.idle":"2024-12-29T18:10:23.389337Z","shell.execute_reply.started":"2024-12-29T18:10:22.676447Z","shell.execute_reply":"2024-12-29T18:10:23.388178Z"}},"outputs":[{"name":"stdout","text":"Skipping sample 0 (468.96)\nSkipping sample 1 (439.19)\nSkipping sample 2 (297.48)\n\nProcessing sample 3...\ntext: sleigh of the magi yuletide cheer is unwrap gifts relax and eat cheer decorations carol sing chimney visit workshop grinch holiday holly jingle naughty nice nutcracker polar beard ornament stocking\nshuffled_text: sleigh polar holiday chimney ornament jingle visit relax yuletide unwrap holly cheer grinch decorations of magi eat carol nutcracker gifts beard cheer sing workshop is nice the stocking naughty and\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffled_text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshuffled_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# 最適化関数の呼び出し\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[43msimulated_annealing_optimize\u001b[49m(shuffled_text, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m正常に終了しました。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m scores\u001b[38;5;241m.\u001b[39mappend(score)\n","\u001b[0;31mNameError\u001b[0m: name 'simulated_annealing_optimize' is not defined"],"ename":"NameError","evalue":"name 'simulated_annealing_optimize' is not defined","output_type":"error"}],"execution_count":19},{"cell_type":"markdown","source":"課題としては\n思うようにスコアが減少しない。\nバッチサイズの問題なのかスタートの温度の問題なのか。\n最初の文字列に依存して得られるスコアが大きく変動しそう。\n","metadata":{}},{"cell_type":"markdown","source":"以下の大きなブラックホールに吸い込まれてしまっている、どう脱出するか。もしくは知被かないかを検討する必要がある。\n\n-New best score: 223.66653284614108\n\n\nNew best text: sleigh yuletide beard carol cheer cheer chimney decorations eat gifts grinch holiday holly jingle is naughty and nice nutcracker ornament of the magi polar relax sing stocking unwrap visit workshop\n\n文章内での複数単語を一単語として計算するとよいスコアが出る可能性がある。そこでどの単語を連語として計算するかを考える必要がある。","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import torch\n\n# デフォルトデバイスをCPUに設定\ndevice = torch.device('cpu')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:10:23.389950Z","iopub.status.idle":"2024-12-29T18:10:23.390243Z","shell.execute_reply.started":"2024-12-29T18:10:23.390099Z","shell.execute_reply":"2024-12-29T18:10:23.390113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}