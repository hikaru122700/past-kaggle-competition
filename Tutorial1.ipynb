{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":88046,"databundleVersionId":10229277,"sourceType":"competition"},{"sourceId":104492,"sourceType":"modelInstanceVersion","modelInstanceId":72255,"modelId":76277}],"dockerImageVersionId":30805,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, you will learn optimization techniques on the subject of Santa-2024 competition.<br>\nsanta-2024のコンペを題材に、最適化手法を学んでいきます。<br>\n1. Issues in Competition (コンペにおける課題) ← this notebook\n2. Greedy (貪欲法)\n3. BS: Beam Search (ビームサーチ)\n4. HC: Hill Climbing (山登り法)\n5. SA: Simulated Annealing (焼きなまし法)\n6. GA: Genetic Algorithm (遺伝的アルゴリズム)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# 1-1. Overview コンペ概要\n- **Data** - You are given a sequence of words separated by spaces. These words are rearranged to create a sequence of words with as little perplexity as possible.<br>\n空白区切りの単語の羅列が与えられます。この単語を並べ替えて、できるだけ複雑性の低い単語の並びを作成します。\n- **Evaluation** - Word sequences are scored by the gemma2 model. The lower the score, the lower the complexity and the better. The overall score is evaluated by averaging the scores for all ids.<br>\n単語の並びをgemma2モデルによりスコア化します。スコアは低いほど複雑性が低く良いことを表します。総合スコアは全てのidに対するスコアの平均値で評価されます。","metadata":{}},{"cell_type":"markdown","source":"# 1-2. Data データ\nLet's look at the data.<br>\nまずはデータを見てみましょう。","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:53:19.501809Z","iopub.execute_input":"2024-12-05T03:53:19.50258Z","iopub.status.idle":"2024-12-05T03:53:19.530448Z","shell.execute_reply.started":"2024-12-05T03:53:19.502523Z","shell.execute_reply":"2024-12-05T03:53:19.529075Z"}}},{"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv('/kaggle/input/santa-2024/sample_submission.csv')\nsample_submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:37:10.701565Z","iopub.execute_input":"2024-12-17T09:37:10.701918Z","iopub.status.idle":"2024-12-17T09:37:10.731959Z","shell.execute_reply.started":"2024-12-17T09:37:10.701887Z","shell.execute_reply":"2024-12-17T09:37:10.731139Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   id                                               text\n0   0  advent chimney elf family fireplace gingerbrea...\n1   1  advent chimney elf family fireplace gingerbrea...\n2   2  yuletide decorations gifts cheer holiday carol...\n3   3  yuletide decorations gifts cheer holiday carol...\n4   4  hohoho candle poinsettia snowglobe peppermint ...\n5   5  advent chimney elf family fireplace gingerbrea...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>advent chimney elf family fireplace gingerbrea...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>advent chimney elf family fireplace gingerbrea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>yuletide decorations gifts cheer holiday carol...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>yuletide decorations gifts cheer holiday carol...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>hohoho candle poinsettia snowglobe peppermint ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>advent chimney elf family fireplace gingerbrea...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"- As of 12/5, six questions were stored.<br>12/5時点では、6つの問題が格納されていました。\n- The sequence of words is stored in the `text` column, separated by spaces.<br>`text`列に単語の並びが空白区切りで格納されています。\n\nLet's check how many words are in each question.<br>それぞれの問題について、単語がいくつあるのか調べてみましょう。","metadata":{}},{"cell_type":"code","source":"word_nums = [len(text) for text in sample_submission.loc[:,'text'].str.split()]\nword_nums","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:37:11.600428Z","iopub.execute_input":"2024-12-17T09:37:11.600704Z","iopub.status.idle":"2024-12-17T09:37:11.609091Z","shell.execute_reply.started":"2024-12-17T09:37:11.600677Z","shell.execute_reply":"2024-12-17T09:37:11.608311Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[10, 20, 20, 30, 50, 100]"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"The later problems had a larger number of words, indicating that the problem was to figure out how to rearrange a maximum of 100 words.<br>後半の問題ほど、単語数が多くなり、最大100個の単語の並び替えを考える問題だということが分かりました。","metadata":{}},{"cell_type":"markdown","source":"# 1-3. Evaluation 評価方法\nThe implementation of the evaluation function is available from the official website<br>\n評価関数の実装は公式から公開されています。<br>\nSanta 2024 Metric: https://www.kaggle.com/code/metric/santa-2024-metric<br>\n<br>\nIt is not necessary to understand all of the code from the beginning. Understand it as needed.<br>最初からコードの内容を全て理解する必要はありません。必要に応じて理解しましょう。","metadata":{}},{"cell_type":"code","source":"\"\"\"Evaluation metric for Santa 2024.\"\"\"\n\nimport gc\nimport os\nfrom math import exp\nfrom collections import Counter\nfrom typing import List, Optional, Union\n\nimport numpy as np\nimport pandas as pd\nimport transformers\nimport torch\n\nos.environ['OMP_NUM_THREADS'] = '1'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nPAD_TOKEN_LABEL_ID = torch.nn.CrossEntropyLoss().ignore_index\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\ndef score(\n    solution: pd.DataFrame,\n    submission: pd.DataFrame,\n    row_id_column_name: str,\n    model_path: str = '/kaggle/input/gemma-2/transformers/gemma-2-9b/2',\n    load_in_8bit: bool = False,\n    clear_mem: bool = False,\n) -> float:\n    \"\"\"\n    Calculates the mean perplexity of submitted text permutations compared to an original text.\n\n    Parameters\n    ----------\n    solution : DataFrame\n        DataFrame containing the original text in a column named 'text'.\n        Includes a row ID column specified by `row_id_column_name`.\n\n    submission : DataFrame\n        DataFrame containing the permuted text in a column named 'text'.\n        Must have the same row IDs as the solution.\n        Includes a row ID column specified by `row_id_column_name`.\n\n    row_id_column_name : str\n        Name of the column containing row IDs.\n        Ensures aligned comparison between solution and submission.\n\n    model_path : str, default='/kaggle/input/gemma-2/transformers/gemma-2-9b/2'\n        Path to the serialized LLM.\n\n    load_in_8bit : bool, default=False\n        Use 8-bit quantization for the model. Requires CUDA.\n\n    clear_mem : bool, default=False\n        Clear GPU memory after scoring by clearing the CUDA cache.\n        Useful for testing.\n\n    Returns\n    -------\n    float\n        The mean perplexity score. Lower is better.\n\n    Raises\n    ------\n    ParticipantVisibleError\n        If the submission format is invalid or submitted strings are not valid permutations.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> model_path = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\"\n    >>> solution = pd.DataFrame({\n    ...     'id': [0, 1],\n    ...     'text': [\"this is a normal english sentence\", \"the quick brown fox jumps over the lazy dog\"]\n    ... })\n    >>> submission = pd.DataFrame({\n    ...     'id': [0, 1],\n    ...     'text': [\"sentence english normal a is this\", \"lazy the over jumps fox brown quick the dog\"]\n    ... })\n    >>> score(solution, submission, 'id', model_path=model_path, clear_mem=True) > 0\n    True\n    \"\"\"\n    # Check that each submitted string is a permutation of the solution string\n    sol_counts = solution.loc[:, 'text'].str.split().apply(Counter)\n    sub_counts = submission.loc[:, 'text'].str.split().apply(Counter)\n    invalid_mask = sol_counts != sub_counts\n    if invalid_mask.any():\n        raise ParticipantVisibleError(\n            'At least one submitted string is not a valid permutation of the solution string.'\n        )\n\n    # Calculate perplexity for the submitted strings\n    sub_strings = [\n        ' '.join(s.split()) for s in submission['text'].tolist()\n    ]  # Split and rejoin to normalize whitespace\n    scorer = PerplexityCalculator(\n        model_path=model_path,\n        load_in_8bit=load_in_8bit,\n    )  # Initialize the perplexity calculator with a pre-trained model\n    perplexities = scorer.get_perplexity(\n        sub_strings\n    )  # Calculate perplexity for each submitted string\n\n    if clear_mem:\n        # Just move on if it fails. Not essential if we have the score.\n        try:\n            scorer.clear_gpu_memory()\n        except:\n            print('GPU memory clearing failed.')\n\n    return float(np.mean(perplexities))\n\n\nclass PerplexityCalculator:\n    \"\"\"\n    Calculates perplexity of text using a pre-trained language model.\n\n    Adapted from https://github.com/asahi417/lmppl/blob/main/lmppl/ppl_recurrent_lm.py\n\n    Parameters\n    ----------\n    model_path : str\n        Path to the pre-trained language model\n\n    load_in_8bit : bool, default=False\n        Use 8-bit quantization for the model. Requires CUDA.\n\n    device_map : str, default=\"auto\"\n        Device mapping for the model.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_path: str,\n        load_in_8bit: bool = False,\n        device_map: str = 'auto',\n    ):\n        self.tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)\n        # Configure model loading based on quantization setting and device availability\n        if load_in_8bit:\n            if DEVICE.type != 'cuda':\n                raise ValueError('8-bit quantization requires CUDA device')\n            quantization_config = transformers.BitsAndBytesConfig(load_in_8bit=True)\n            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n                model_path,\n                quantization_config=quantization_config,\n                device_map=device_map,\n            )\n        else:\n            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n                model_path,\n                torch_dtype=torch.float16 if DEVICE.type == 'cuda' else torch.float32,\n                device_map=device_map,\n            )\n\n        self.loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n\n        self.model.eval()\n\n    def get_perplexity(\n        self, input_texts: Union[str, List[str]], debug=False\n    ) -> Union[float, List[float]]:\n        \"\"\"\n        Calculates the perplexity of given texts.\n\n        Parameters\n        ----------\n        input_texts : str or list of str\n            A single string or a list of strings.\n\n        batch_size : int, default=None\n            Batch size for processing. Defaults to the number of input texts.\n\n        debug : bool, default=False\n            Print debugging information.\n\n        Returns\n        -------\n        float or list of float\n            A single perplexity value if input is a single string,\n            or a list of perplexity values if input is a list of strings.\n\n        Examples\n        --------\n        >>> import pandas as pd\n        >>> model_path = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\"\n        >>> scorer = PerplexityCalculator(model_path=model_path)\n\n        >>> submission = pd.DataFrame({\n        ...     'id': [0, 1, 2],\n        ...     'text': [\"this is a normal english sentence\", \"thsi is a slihgtly misspelled zr4g sentense\", \"the quick brown fox jumps over the lazy dog\"]\n        ... })\n        >>> perplexities = scorer.get_perplexity(submission[\"text\"].tolist())\n        >>> perplexities[0] < perplexities[1]\n        True\n        >>> perplexities[2] < perplexities[0]\n        True\n\n        >>> perplexities = scorer.get_perplexity([\"this is a sentence\", \"another sentence\"])\n        >>> all(p > 0 for p in perplexities)\n        True\n\n        >>> scorer.clear_gpu_memory()\n        \"\"\"\n        single_input = isinstance(input_texts, str)\n        input_texts = [input_texts] if single_input else input_texts\n\n        loss_list = []\n        with torch.no_grad():\n            # Process each sequence independently\n            for text in input_texts:\n                # Explicitly add sequence boundary tokens to the text\n                text_with_special = f\"{self.tokenizer.bos_token}{text}{self.tokenizer.eos_token}\"\n\n                # Tokenize\n                model_inputs = self.tokenizer(\n                    text_with_special,\n                    return_tensors='pt',\n                    add_special_tokens=False,\n                )\n\n                if 'token_type_ids' in model_inputs:\n                    model_inputs.pop('token_type_ids')\n\n                model_inputs = {k: v.to(DEVICE) for k, v in model_inputs.items()}\n\n                # Get model output\n                output = self.model(**model_inputs, use_cache=False)\n                logits = output['logits']\n\n                # Shift logits and labels for calculating loss\n                shift_logits = logits[..., :-1, :].contiguous()  # Drop last prediction\n                shift_labels = model_inputs['input_ids'][..., 1:].contiguous()  # Drop first input\n\n                # Calculate token-wise loss\n                loss = self.loss_fct(\n                    shift_logits.view(-1, shift_logits.size(-1)),\n                    shift_labels.view(-1)\n                )\n\n                # Calculate average loss\n                sequence_loss = loss.sum() / len(loss)\n                loss_list.append(sequence_loss.cpu().item())\n\n                # Debug output\n                if debug:\n                    print(f\"\\nProcessing: '{text}'\")\n                    print(f\"With special tokens: '{text_with_special}'\")\n                    print(f\"Input tokens: {model_inputs['input_ids'][0].tolist()}\")\n                    print(f\"Target tokens: {shift_labels[0].tolist()}\")\n                    print(f\"Input decoded: {self.tokenizer.decode(model_inputs['input_ids'][0])}\")\n                    print(f\"Target decoded: {self.tokenizer.decode(shift_labels[0])}\")\n                    print(f\"Individual losses: {loss.tolist()}\")\n                    print(f\"Average loss: {sequence_loss.item():.4f}\")\n\n        ppl = [exp(i) for i in loss_list]\n\n        if debug:\n            print(\"\\nFinal perplexities:\")\n            for text, perp in zip(input_texts, ppl):\n                print(f\"Text: '{text}'\")\n                print(f\"Perplexity: {perp:.2f}\")\n\n        return ppl[0] if single_input else ppl\n\n    def clear_gpu_memory(self) -> None:\n        \"\"\"Clears GPU memory by deleting references and emptying caches.\"\"\"\n        if not torch.cuda.is_available():\n            return\n\n        # Delete model and tokenizer if they exist\n        if hasattr(self, 'model'):\n            del self.model\n        if hasattr(self, 'tokenizer'):\n            del self.tokenizer\n\n        # Run garbage collection\n        gc.collect()\n\n        # Clear CUDA cache and reset memory stats\n        with DEVICE:\n            torch.cuda.empty_cache()\n            torch.cuda.ipc_collect()\n            torch.cuda.reset_peak_memory_stats()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:37:12.051770Z","iopub.execute_input":"2024-12-17T09:37:12.052007Z","iopub.status.idle":"2024-12-17T09:37:12.071211Z","shell.execute_reply.started":"2024-12-17T09:37:12.051984Z","shell.execute_reply":"2024-12-17T09:37:12.070418Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"- First initialize the scorer, which takes about 3 minutes.<br>\n最初にスコアラーを初期化します。3分ほど時間がかかります。<br>\n- If an OSError occurs, please make an access request at the following URL.<br>\nOSErrorが出る場合、次のURLからアクセスリクエストを行ってください。<br>\nGemma Access Request: https://www.kaggle.com/models/google/gemma/license/consent","metadata":{}},{"cell_type":"code","source":"%%time\nscorer = PerplexityCalculator('/kaggle/input/gemma-2/transformers/gemma-2-9b/2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:37:12.348716Z","iopub.execute_input":"2024-12-17T09:37:12.348935Z","iopub.status.idle":"2024-12-17T09:39:52.541746Z","shell.execute_reply.started":"2024-12-17T09:37:12.348913Z","shell.execute_reply":"2024-12-17T09:39:52.540825Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe9c26ee9a3e40faaca897a8f509b3ef"}},"metadata":{}},{"name":"stdout","text":"CPU times: user 23.4 s, sys: 38.2 s, total: 1min 1s\nWall time: 2min 40s\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Once initialization is complete, you can then run `get_perplexity()` with the text you wish to evaluate as an argument to obtain a score.<br>\n初期化が終われば、あとは評価したいテキストを引数に`get_perplexity()`を実行することで、スコアを得ることができます。","metadata":{}},{"cell_type":"code","source":"text = sample_submission.loc[0,'text']\ntext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:39:52.543671Z","iopub.execute_input":"2024-12-17T09:39:52.544054Z","iopub.status.idle":"2024-12-17T09:39:52.550145Z","shell.execute_reply.started":"2024-12-17T09:39:52.544013Z","shell.execute_reply":"2024-12-17T09:39:52.549198Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"score = scorer.get_perplexity(text)\nscore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:39:52.551067Z","iopub.execute_input":"2024-12-17T09:39:52.551385Z","iopub.status.idle":"2024-12-17T09:39:55.171762Z","shell.execute_reply.started":"2024-12-17T09:39:52.551360Z","shell.execute_reply":"2024-12-17T09:39:55.170911Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"3887.9021574548156"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"`get_perplexity()` can also accept more than one answer at a time.<br>\n`get_perplexity()`は、一度に複数の回答も受け付けてくれます。","metadata":{}},{"cell_type":"code","source":"texts = sample_submission.loc[:, 'text']\ntexts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:39:55.174006Z","iopub.execute_input":"2024-12-17T09:39:55.174660Z","iopub.status.idle":"2024-12-17T09:39:55.181318Z","shell.execute_reply.started":"2024-12-17T09:39:55.174618Z","shell.execute_reply":"2024-12-17T09:39:55.180178Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0    advent chimney elf family fireplace gingerbrea...\n1    advent chimney elf family fireplace gingerbrea...\n2    yuletide decorations gifts cheer holiday carol...\n3    yuletide decorations gifts cheer holiday carol...\n4    hohoho candle poinsettia snowglobe peppermint ...\n5    advent chimney elf family fireplace gingerbrea...\nName: text, dtype: object"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"scores = scorer.get_perplexity(texts)\nscores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:39:55.182323Z","iopub.execute_input":"2024-12-17T09:39:55.182621Z","iopub.status.idle":"2024-12-17T09:40:04.830697Z","shell.execute_reply.started":"2024-12-17T09:39:55.182595Z","shell.execute_reply":"2024-12-17T09:40:04.829834Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[3887.9021574548156,\n 6068.929443212337,\n 1118.2623094137844,\n 1287.112028449327,\n 353.25405478056325,\n 354.636652059297]"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"If you submit your response as is, the average of the six scores will be your score.<br>\nこのままで回答を提出した場合、6つのスコアの平均が総合スコアとなります。","metadata":{"execution":{"iopub.status.busy":"2024-12-05T07:25:04.602101Z","iopub.execute_input":"2024-12-05T07:25:04.602452Z","iopub.status.idle":"2024-12-05T07:25:04.608423Z","shell.execute_reply.started":"2024-12-05T07:25:04.602426Z","shell.execute_reply":"2024-12-05T07:25:04.60732Z"}}},{"cell_type":"code","source":"print('Average Perplexity:', np.mean(scores))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:40:04.831586Z","iopub.execute_input":"2024-12-17T09:40:04.831837Z","iopub.status.idle":"2024-12-17T09:40:04.836650Z","shell.execute_reply.started":"2024-12-17T09:40:04.831812Z","shell.execute_reply":"2024-12-17T09:40:04.835836Z"}},"outputs":[{"name":"stdout","text":"Average Perplexity: 2178.3494408950205\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# 1-4. Issues 課題\nThe challenge of this competition is to find the best solution possible in a limited time from a huge number of solutions.<br>\nTo understand why it is so difficult to find the best solution, we will try to solve the problem using a technique called the full search algorithm.<br>\nBefore solving the actual problem, I created a simple problem by reducing the number of words from the `id=0` problem.\n\n\nこのコンペの課題は、膨大な解の中から限られた時間でできるだけ良い解を発見しなければいけないことです。<br>\nなぜ最適な解を見つけるのが難しいのか理解するために、全探索法という手法で問題を解いてみます。<br>\n実際の問題を解く前に、`id=0` の問題から単語を減らして簡単な問題を作成してみました。","metadata":{}},{"cell_type":"code","source":"words = sample_submission.loc[0,'text'].split()\nwords = words[:5]\nwords","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:40:04.837776Z","iopub.execute_input":"2024-12-17T09:40:04.838116Z","iopub.status.idle":"2024-12-17T09:40:04.850121Z","shell.execute_reply.started":"2024-12-17T09:40:04.838070Z","shell.execute_reply":"2024-12-17T09:40:04.849421Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['advent', 'chimney', 'elf', 'family', 'fireplace']"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"Rearrange these five words to find the solution with the lowest score.<br>\nThe full search algorithm evaluates and searches all possible solutions. Let's enumerate the possible solutions using `itertools.permutations`.\n\nこの5つの単語を並び替えて、最もスコアが低くなる解を見つけましょう。<br>\r\n全探索法は、考えられる解を全て評価して探索します。`itertools.permutations`を用いて考えられる解を列挙してみます。","metadata":{}},{"cell_type":"code","source":"import itertools\nall_permutations = list( itertools.permutations(words) )[::-1]\nprint('number of pattern：', len(all_permutations))\nprint('example pattern')\nall_permutations[:3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:40:04.851051Z","iopub.execute_input":"2024-12-17T09:40:04.851324Z","iopub.status.idle":"2024-12-17T09:40:04.863523Z","shell.execute_reply.started":"2024-12-17T09:40:04.851299Z","shell.execute_reply":"2024-12-17T09:40:04.862699Z"}},"outputs":[{"name":"stdout","text":"number of pattern： 120\nexample pattern\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[('fireplace', 'family', 'elf', 'chimney', 'advent'),\n ('fireplace', 'family', 'elf', 'advent', 'chimney'),\n ('fireplace', 'family', 'chimney', 'elf', 'advent')]"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"We have $120$($=5!$) possible combinations.<br>\nNow let's evaluate all $120$ solutions and find the solution with the best score.<br>\n\n組み合わせは、$120$通りできました。$5!$ (5の階乗)通りです。<br>\r\nそれでは、$120$通り全ての解を評価して、最も良いスコアの解を探しましょう。","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nbest_score = 1e6\nbest_text = \"\"\n\nfor words in tqdm(all_permutations):\n    text = ' '.join(words)\n    score = scorer.get_perplexity(text)\n    if score < best_score:\n        best_score = score\n        best_text = text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:40:04.864476Z","iopub.execute_input":"2024-12-17T09:40:04.864776Z","iopub.status.idle":"2024-12-17T09:43:09.382417Z","shell.execute_reply.started":"2024-12-17T09:40:04.864752Z","shell.execute_reply":"2024-12-17T09:43:09.381476Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 120/120 [03:04<00:00,  1.54s/it]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(f'best score : {best_score}')\nprint(f'{best_text}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:43:09.384528Z","iopub.execute_input":"2024-12-17T09:43:09.384797Z","iopub.status.idle":"2024-12-17T09:43:09.389294Z","shell.execute_reply.started":"2024-12-17T09:43:09.384771Z","shell.execute_reply":"2024-12-17T09:43:09.388316Z"}},"outputs":[{"name":"stdout","text":"best score : 38356.81513988041\nchimney elf fireplace family advent\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"The optimal solution has been obtained. Since the full search algorithm searches for all solutions, it can always find the optimal solution.<br>\nIt took about 10 seconds to evaluate 120 different ways.<br>\nSo how long does it take to solve the actual problem?<br>\n- For `id=0` with 10 words, the number of possible solutions is $10!=3,628,800$, which is 30,240x and takes about 5 days.\n- For `id=5`, which has the highest number of words, the number of possible solutions seems to be $100!=9\\times10^{157}$, which takes $2.8\\times10^{151}$ years.\nAs the number of words increases in this way, the number of extreme combinations becomes enormous. This is called a combinatorial explosion.<br>\nBefore the earth is swallowed by the sun 5 billion years from now, before our life is over, and most importantly before the end of the competition period, we will need a algorithm to find a solution that scores as well as possible in an efficient manner.<br>\n\n最適解が求まりました。全探索法は全ての解を探索するため、必ず最適解を求めることができます。<br>\n今回は、120通りの評価に、約10秒かかりました。\nでは、実際の問題を解こうとすると、どれくらい時間がかかるでしょうか。<br>\n- 単語数10個の `id=0` は、考えられる解の数は $10!=3,628,800$ 通り、30,240倍で約5日かかる計算になります。<br>\n- 最も単語数の多い `id=5` では、考えられる解の数は $100!=9\\times10^{157}$ 通り、単純計算で$2.8\\times10^{151}$年かかるようです。<br>\n\nこのように単語数が増えると、極端に組み合わせ数は膨大になっていきます。これは組み合わせ爆発と呼ばれます。<br>\n50億年後地球が太陽に飲み込まれる前に、自分の人生が終わる前に、何よりコンペ期間が終わる前に、効率よくできるだけスコアの良い解を見つける手法が必要になります。","metadata":{}},{"cell_type":"markdown","source":"# 1-5. Submission 提出\nFinally, to practice the submission process, let's partially perform the full search algorithm introduced in this article and submit our answers.<br>\nOf the given words, rearrange only the first 5 words to evaluate $120$ possible solutions and submit the solution with the highest score as your answer.<br>\n\r\n最後に、提出の練習も兼ねて、今回紹介した全探索法を部分的に実行して回答を提出してみましょう。<br>\r\n与えられた単語のうち、最初の5単語のみ並べ替えて$120$通りの解を評価し、その中で最もスコアの高い解を回答として提出します。","metadata":{}},{"cell_type":"code","source":"def explore_first_five_permutations(text):\n    words = text.split()\n    words_head = words[:5]\n    words_tail = ' '.join(words[5:])\n\n    best_score = 1e6\n    best_text = \"\"\n    \n    all_permutations = list(itertools.permutations(words_head))[::-1]\n    for words_head in all_permutations:\n        text = ' '.join(words_head) + ' ' + words_tail\n        score = scorer.get_perplexity(text)\n        if score < best_score:\n            best_score = score\n            best_text = text\n\n    return best_score, best_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:43:09.390330Z","iopub.execute_input":"2024-12-17T09:43:09.390560Z","iopub.status.idle":"2024-12-17T09:43:09.401209Z","shell.execute_reply.started":"2024-12-17T09:43:09.390537Z","shell.execute_reply":"2024-12-17T09:43:09.400287Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"best_scores = []\nbest_texts = []\nfor i in tqdm(range(6)):\n    text = sample_submission.loc[i,'text']\n    best_score, best_text = explore_first_five_permutations(text)\n    best_scores.append(best_score)\n    best_texts.append(best_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:43:09.402296Z","iopub.execute_input":"2024-12-17T09:43:09.402544Z"}},"outputs":[{"name":"stderr","text":" 50%|█████     | 3/6 [09:38<09:40, 193.58s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"best_scores","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Initial Average Perplexity:', np.mean(scores))\nprint('Improved Average Perplexity:', np.mean(best_scores))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission['improved_text'] = best_texts\nsample_submission['score'] = scores\nsample_submission['improved_score'] = best_scores\nsample_submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For all ids, we were able to improve the scores. Finally, only the required columns are extracted and saved as `submission.csv`.<br>\n全てのidについて、スコアを改善できました。最後に必要な列のみを抽出してcsvとして保存することで提出します。","metadata":{}},{"cell_type":"code","source":"sub = sample_submission[['id', 'improved_text']]\nsub = sub.rename(columns={'improved_text':'text'})\nsub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Next issue, you will learn how to improve your score using the greedy algorithm.<br>\n次回は、貪欲法によるスコアの改善方法を学びます。","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}